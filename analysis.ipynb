{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Online Shoppers Intention Analysis\n",
        "\n",
        "## Project Overview\n",
        "This project analyzes the Online Shoppers Purchasing Intention Dataset to predict whether a visitor will make a purchase ('Revenue').\n",
        "\n",
        "**Goals:**\n",
        "1. Data Preprocessing (Cleaning, Encoding, Scaling)\n",
        "2. Exploratory Data Analysis (EDA)\n",
        "3. Model Building (Logistic Regression, Random Forest)\n",
        "4. Model Evaluation & Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "# Settings\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Data\n",
        "df = pd.read_csv('online_shoppers_intention.csv')\n",
        "print(f\"Initial Shape: {df.shape}\")\n",
        "\n",
        "# Check for duplicates and missing values\n",
        "print(f\"Duplicates: {df.duplicated().sum()}\")\n",
        "df.drop_duplicates(inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "print(f\"Shape after cleaning: {df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Exploratory Data Analysis (EDA)\n",
        "Visualizing key feature distributions and correlations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation Heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "numeric_df = df.select_dtypes(include=['float64', 'int64'])\n",
        "sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n",
        "\n",
        "# Pattern: PageValues vs Revenue\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='Revenue', y='PageValues', data=df)\n",
        "plt.title('PageValues vs Revenue')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Preprocessing\n",
        "Encoding categorical variables and scaling numerical features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encoding\n",
        "df['Weekend'] = df['Weekend'].astype(int)\n",
        "df['Revenue'] = df['Revenue'].astype(int)\n",
        "df = pd.get_dummies(df, columns=['Month', 'VisitorType'], drop_first=True)\n",
        "\n",
        "# Scaling\n",
        "numerical_cols = ['Administrative', 'Administrative_Duration', 'Informational', \n",
        "                  'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration', \n",
        "                  'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay']\n",
        "scaler = StandardScaler()\n",
        "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "# Splitting\n",
        "X = df.drop('Revenue', axis=1)\n",
        "y = df['Revenue']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training Set: {X_train.shape}\")\n",
        "print(f\"Testing Set: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Building and Evaluation\n",
        "comparing Logistic Regression and Random Forest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(model, name):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"--- {name} ---\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    \n",
        "    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix: {name}')\n",
        "    plt.show()\n",
        "\n",
        "# Logistic Regression\n",
        "evaluate_model(LogisticRegression(max_iter=1000, random_state=42), \"Logistic Regression\")\n",
        "\n",
        "# Random Forest\n",
        "evaluate_model(RandomForestClassifier(n_estimators=100, random_state=42), \"Random Forest\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
